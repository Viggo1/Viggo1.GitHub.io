---
layout: post                  
title: "随手整理之PyTorch常用函数"  
date: 2022-09-30 21:06:20+08:00  
categories: ["DL"]  # 对应分类
tags: [DL,PyTorch]  # 细化主题，方便搜索（3-5个）
# cover: /assets/images/covers/文章封面图.jpg  可选：文章封面图（放在assets对应文件夹）
---

写完今天的课程作业，整理一下PyTorch常用的函数等等

# 数据处理

- 数据加载
	- __getitem\_\_： 返回一条数据或一个样本
	obj[index] 等价于 obj.__getitem__(index)
	- __len__:
	len(obj) obj.__len__()
	- example:
	```
	
	```
	- ImageFolder
	- 采样模块sampler
		- SequentialSampler默认采样器，按序采样
		- RandomSampler随机采样器，打乱数据（dataloader中shuffle=True）
		- WeightedRandomSampler按权重选取
		样本权重weights，样本总数num_samples，[replacement是否放回]
	- 注意：
		- 高负载的操作（如加载图片）放在getitem中
		多进程并行调用此函数，可加速。
		- dataset中尽量只包含只读对象，避免修改任何可变对象
		dataloader多进程加载可变对象可能发生冲突且不会报错。
		修改可变对象建议使用Queue库中的数据结构
		- 手动终止进程p145
* * *
- torchvision
	- models：深度学习经典网络结构，预训练好的模型（Alex-Net,VGG,ResNet,Inception）
	- datasets：常用的数据集加载（MNIST,CIFAR10/100,ImageNet,COCO），设计上继承torch.utils.data.Dataset
	- transforms：数据预处理，主要对于Tensor，PIL Image对象
		- 转换分为两步：
		```
		transf=transforms.Normalize(mean=x,std=y) #构建转换操作
		output=transf(input) #执行
		```
	- 常用函数
		- make_grid 多张图拼接成网格（数据增强）
		- save_img 将Tensor存为图片
- 可视化工具p150
	- TensorBorad
	- visdom
* * *
- GPU加速
在pytorch中Tensor、Variable（包括Parameter）、nn.Module分为CPU和GPU两个版本，都带有.cuda的方法，其中前两个会返回迁移后的新对象，第三者会迁移后返回自己
```
if t.cuda.is_available():
		x=x.cuda()
		
torch.cuda.device() #指定默认使用哪块GPU

torch.set_default_tensor_type('torch.cuda.FloatTensor') #指定默认tensor的类型为GPU上的FloatTensor
```


>数据在CPU，GPU传递十分耗时，且计算量大时加速效果才明显，注意权衡



## 可视化工具
### TensorBoard

- add_scalar()

	- tag(data identifier)
	- scalar_value(save) y
	- global_step(record) x
	- walltime()
```python
# add_scalar(self,tag,scalar_value,global_step=None,walltime=None)

from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter("logs") #选择存储的文件夹

for i in range(100):
	writer.add_scalar("y=2x",2*i,i)
	
writer.close()
# 错误解决：多个图像互相拟合干扰，可以删除目标文件夹的内容或杀掉进程；建议新内容写入子文件夹
```


- add_image()
	- tag(string)
	- img_tensor(image data,type=numpy.array/tensor)
	- globel_step(record)
	- walltime()
```python
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter("logs") #选择存储的文件夹

import numpy as np
from PIL import Image
image_path=""
img_PIL=Image.open(image_path)
img_array=np.array(img_PIL) #转换图像数据类型为np.ndarray

writer.add_image("test",img_array,1,dataformats='HWC')
# 从PIL到numpy，需要指定shape中每一维表示的含义，默认CHW
# 可以查看shape或者使用print(img_array.shape)显示
for i in range(100):
	writer.add_scalar("y=2x",2*i,i)
	
writer.close()
```

### visdom
创造组织共享多种数据可视化（数值、图像、文本、视频）
支持PyTorch、Torch、Numpy
- env 环境：不同环境里的可视化结果相互隔离互不影响
	不同用户、不同程序一般使用不同env，不指定则默认使用main
- pane 窗格：可视化图像、数值、打印文本等 某一信息
		拖动、缩放、保存、关闭
	
- 注意
	- visdom是一个Web Server服务。默认绑定8097端口，客户端与服务器通过tornado非阻塞交互，网络异常不会退出；
	通过`python -m visdom.server`启动服务或`nohup python -m visdom.server &`后台运行
	- 需使用save手动保存env否则重启丢失
```python
nohup python -m visdom.server & #后台运行

import visdom
#新建连接客户端，指定env，端口默认8097，host默认 'localhost'
vis = visdom.Visdom(env=u'test1')

x=t.arange(1,30,0.01)
y=t.sin(x)
vis.line(X=x,Y=y,win='sinx',opts={'title':'y=sin(x)'})
#win指定pane的名字，同样名称覆盖旧的
#opts设置pane的显示格式，接收字典，包括title,xlabel,ylabel,width
```
- visdom支持tensor和ndarray，不支持int，float
- vis作为客户端对象，可使用函数：
>line——标量变化（loss，acc）
>image——图片（输入，GAN生成，卷积核信息）
>text——文字，支持HTML
>histgram——分布（数据，参数）
>scatter——散点图
>bar——柱状图
>pie——饼状图
- 浏览器输入http://localhost:8097 看到结果
- 避免覆盖之前的数值
	- 指定参数update='append'
	```python
	for ii in range(0,10):
		x=t.Tensor([ii])
		y=x
		vis.line(X=x,Y=y,win='polynomial',update='append' if ii>0 else None)
		#追加数据
	```
	- vis.updateTrace在指定pane上新增独立trace，还可以在同一条trace上追加数据
	```python
	x=t.arange(0,9,0.1)
	y=(x**2)/9
	vis.updataTrace(X=x,Y=y,win='polynominal',name='this is a new Trace')
	#新增一条线
	```
- image
	- 二维向量H×W~黑白图像~
	- 三维向量3×H×W~彩色图像~
- images： 四维图像N×C×H×W~C取值1or3~实现多张图片拼接
```python
vis.image(t.randn(64,64).numpy())
vis.images(t.randn(36,3,64,64).numpy(),nrow=6,win='random',
		   opts={'title':'random_images'})
#可视化36张随机的彩色图片，每行6张
```
- text
	- 换行使用<br\>



## transforms
- ToTensor 
将 PIL image （Image.open）或者 numpy.ndarray （opencv.imread） 转换为 tensor

- Normalize 标准化
- Resize
- Compose
参数格式为列表，类型为transforms
Compose([transforms参数1,transforms参数2,...])
参数1的输出作为参数2的输入
- RandomCrop裁剪


# Tensor
重要的数据结构，可以是标量（数），向量（一维数组），矩阵（二维数组）或高维数组
>与numpy的ndarrays类似，但可使用GPU 加速；使用和numpy、MATLAB的接口相似


```Python
from __future__ import print_function
import torch as t

x=t.Tensor(5,3) #指定形状，分配空间未初始化
x=t.Tensor(y.size())

x=t.Tensor([[1,2,3],[4,5,6]]) #list

x=t.Tensor((2,3)) #tuple 单列


x=t.rand(5,3) #[0,1]均匀分布随机初始化二维数组
x=t.randn(2,3) #[2,3]标准分布

x=t.arange(start,end,step) #[start,end）step=1

x=t.linspace(start,end,parts) #[start,end]

x=t.randperm(5) #单列长度为5随机排列

x=t.eye(2,3) #对角线为1其余为0，2行3列

x.size() #查看矩阵x形状
x.shape


x.size()[0] #查看矩阵x行数
#torch.size是tuple对象的子类，支持tuple的所有操作

x.numel()
x.nelement() #计算元素总数
```
- view()
元素个数不变，重构张量维度
	- 参数代表对应维度的元素数，设置为-1表示自由匹配其余参数（保证元素个数不变 ）
	 - torch.view(-1)，则原张量会变成一维的结构
	- example
	```
	res.scatter(1,x.view(-1,1),1)
	
	```

- resize_

.
### 索引
```python
x[0] #第0行

x[:2] #前两行
# x[t.LongTensor([0,1])] 等价

x[:,1] #第1列

x[:2,0:2] #前两行的第0，1列
x[0:1,:2] #第0行的前两列


a[0][2]   
a[0,2] #第0行第2列元素

a[0,-1] #第0行最后一个元素


```
-  LongTensor()
	- 索引需要当作LongTensor传入
	- example![2a56d113361c96d972833c86469aa344.png](:/93295443dd5649758c5ba3860ac09b10)
源元素与索引一一对应，按行传递时，索引与目标列列对应，第几行由索引值指定，将对应的源元素放入指示位置，索引有几行就扫描传入几次
- >![9e3270bac132cc38e29950838410ebe1.png](:/f7071f6fd45948a39ecebf8a8184ec01)




- gather(input,dim,index)
	- 根据index在dim维度上选取数据
	- 
	```
	index=t.LongTensor([[0,1,2]]) #对角线元素索引
	a.gather(0,index) #1行0 4 8
	index=t.LongTensor([[2,1,0]]).t() #反对角线元素索引
	a.gather(1,index) #1列2 4 6
	```
	
- 逆操作 scatter_(input, dim, index, src)

- 将src中数据根据index中的索引按照dim的方向填进input。可以理解成放置元素或者修改元素     

	- dim：沿着哪个维度进行索引
	- index：用来 scatter 的元素索引
	- src：用来 scatter 的源元素，可以是一个标量或一个张量




* * *

- 选择函数
	- a>1 返回ByteTensor（符合条件处1，其余0）
	- a[a>1]等价于a.masked_select(a>1) 按条件筛选，返回原Tensor格式符合条件部分
- masked_select(input,mask)
* * *

- Tensor和numpy数组间互操作
它们的对象形式不同共享内存，因此转换很快，内容修改也会相互影响

```
a=t.ones(5) #新建单列全1FloatTensor
b=a.numpy() #转为numpy数组(一行浮点)

a=np.ones(5) #新建5元素全1数组
b=t.from_numpy(a) #转为单列全1DoubleTensor
```

* * *
## 运算
.
加法
```
x+y

t.add(x,y)

result=t.Tensor(5,3)
t.add(x,y,out=result)
result

#三种方式显示相同结果

```
- 有无下划线
	- 无下划线创建新Tensor返回结果
		-  y.add(x)	
	-	有下划线修改y本身
		-	 y.add_(x)

### 广播法则

- unsqueeze
- squeeze
- expand




* * *
* * *
* * *
注意
- 大多数t.function都有参数out，结果保存在此指定tensor
- t.set_num_threads 限制CPU多线程并行计算时占用的线程数
- t.set_printoptions用来设置打印tensor时的数值精度和格式
	
	```
	t.set_printptions(precision=10) #小数点后十位
	```
	
- 低精度使用HalfTensor省时(注意数值溢出)
- 

-  Tensor() or tensor()
- ![a3c67f8c7ae5fb8430fb4f81504586e5.png](:/d4f85a567f3142bd9028b41b83354e7e)




[Tensor常用函数](https://www.jianshu.com/p/d678c5e44a6b)

