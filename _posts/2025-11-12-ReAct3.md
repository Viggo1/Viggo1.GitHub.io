---
layout: post                  
title: "Dify实战--从DeepResearch到简历优化智能体"  
date: 2025-11-12 21:44:09+08:00  
categories: ["Agent"]  # 对应分类
tags: [Agent,ReAct,LLM]  # 细化主题，方便搜索（3-5个）
# cover: /assets/images/covers/文章封面图.jpg  可选：文章封面图（放在assets对应文件夹）
---


## 实战：如何基于ReAct/DeepResearch搭建智能体？
以“简历优化智能体”为例，学习基于ReAct范式的落地步骤：  

### 1.1 核心步骤：从0到1搭建ReAct智能体
#### （1）定义任务目标与工具
- 目标：“接收用户简历+岗位方向，输出基于实时大厂标准的优化建议”；  
- 工具清单：  
  - 招聘平台API（获取实时岗位关键词）；  
  - 知识库检索（获取简历量化案例）；  
  - 文本分析工具（提取用户简历中的现有关键词）。

#### （2）设计ReAct循环节点（可视化/代码）
以LangGraph（智能体开发工具）为例，拆解为3个核心节点：  
1. **Reasoning节点**（思考）：  
   - 输入：用户简历、岗位方向、历史记录；  
   - 提示词模板：  
     ```
     基于以下信息推理下一步行动：
     1. 用户信息：简历={resume}，岗位={position}；
     2. 已获取数据：{history_data}；
     3. 需判断：是否缺关键信息（如大厂标准、量化案例）？下一步调用哪个工具？
     输出JSON：{"need_action": true/false, "action_type": "api/knowledge", "action_param": "..."}
     ```
2. **Acting节点**（行动）：  
   - 功能：根据Reasoning输出调用对应工具，返回结构化结果；  
3. **Observation节点**（观察）：  
   - 功能：评估工具结果质量（如“是否获取到2025年关键词”），并将结果存入历史记录。

#### （3）配置循环终止条件
- 主动终止：Observation节点判断“已获取所有关键信息”；  
- 被动终止：循环达到最大轮次（如3轮），避免无限检索。

#### （4）升级为DeepResearch模式
若需提升深度，可增加两步：  
1. 引入**异步任务管理器**：用Redis存储历史记录，每轮仅传递增量数据；  
2. 配置**多Agent并行**：分别创建“关键词检索Agent”“案例检索Agent”，最终融合结果。


### 1.2 避坑指南：落地ReAct的常见错误
1. **思考环节过度简化**：仅输出“调用工具”，不说明原因——导致后续无法追溯逻辑，建议强制AI输出完整推理链；  
2. **行动环节工具过载**：调用过多工具（如同时查10个招聘网站）——建议每轮仅调用1个工具，聚焦核心目标；  
3. **观察环节缺乏质量评估**：仅判断“是否有结果”，不评估“结果是否有用”——建议从“覆盖度、精准度、完整性”三维度评估。

### 1.3 小试牛刀——低代码平台Dify工作流/智能体搭建
1. 项目背景
在求职场景中，用户常需针对自身简历的优化方向（如内容匹配度、排版逻辑、关键词适配等）获取精准建议，但传统简历分析工具存在检索不充分（仅基于单轮信息）、判断片面（缺乏动态补充机制）等问题。本项目基于 Dify 平台搭建「简历优化智能体」，通过多轮检索 + 动态判断的闭环逻辑，实现更全面、精准的简历分析与优化建议生成。
2. 核心功能
自动拆解用户简历相关问题为可检索子问题；
基于知识库完成多轮检索（含初始检索 + 补充检索）；
动态判断检索充分性，自动终止或继续进行浏览器补充检索；
整合全量检索结果主导的回答，生成结构化简历优化建议。
3. 技术栈
开发平台：Dify（可视化工作流 + 自定义代码块）；
核心机制：全局变量管理 + 循环检索逻辑 + LLM 判断；
依赖工具：大语言模型（LLM）、知识库检索接口。

#### 4.核心模块说明
| 模块名称         | 功能描述                                                                 | 技术实现                          |
|------------------|--------------------------------------------------------------------------|-----------------------------------|
| 问题拆解模块     | 将用户原始问题（如“我的简历如何匹配产品经理岗位？”）拆解为2-5个可检索子问题（如“产品经理岗位核心要求”“简历关键词优化方法”） | LLM提示词工程+数组格式化处理      |
| 全局变量管理模块 | 存储累计检索结果（`finding`）和已检索主题（`topic`），支持跨循环读写       | Dify全局变量+代码块更新逻辑       |
| 检索执行模块     | 基于子问题/补充主题调用知识库检索接口，返回结构化结果                       | 知识库API调用+结果格式化          |
| 循环判断模块     | 基于当前检索结果判断是否需继续补充检索，输出判断结果和下一个检索主题         | LLM结构化输出（JSON格式）+逻辑校验 |
| 结果生成模块     | 整合全量检索结果，生成符合用户需求的简历优化建议                             | 提示词模板+LLM生成                |


#### 5. 搭建流程（基于Dify）
（1） 前置准备
- 配置Dify环境：部署Dify社区版/使用云平台实例，关联知识库（需包含简历优化、岗位要求等领域数据）；
- 准备工具：绑定LLM模型（如GPT-3.5/4、通义千问等），配置API密钥；
- 定义变量：预设全局变量`finding`（存储累计检索结果，字符串类型）和`topic`（存储已检索主题，数组类型）。


（2）关键步骤
步骤：问题拆解模块配置
- **功能**：将用户输入的自然语言问题拆解为子问题数组；
- **实现**：
  1. 添加「LLM节点」，输入提示词模板：
     ```
     请将用户关于简历优化的问题拆解为2-5个可检索的子问题，仅返回JSON数组（示例：["子问题1", "子问题2"]）。
     用户问题：{{user_input}}
     ```
  2. 添加「代码块」对LLM输出进行格式化，提取子问题数组（`sub_questions_array`）：
     ```python
     def main(llm_output: str) -> dict:
         import json
         try:
             # 提取JSON数组
             sub_questions = json.loads(llm_output)
             # 清洗空值和空格
             return {"sub_questions_array": [q.strip() for q in sub_questions if q.strip()]}
         except:
             # 容错：默认子问题
             return {"sub_questions_array": ["简历核心优化维度", "目标岗位匹配要点"]}
     ```


步骤：检索执行与循环更新模块
- **功能**：执行初始检索+补充检索，通过全局变量累计结果；
- **实现**：
  1. **初始检索**：添加「检索节点」，输入子问题数组`{{sub_questions_array}}`，输出格式化结果`formatted_finding`，关联至步骤2的初始化模块；
  2. **循环判断**：添加「LLM节点」判断是否需补充检索，输入提示词：
     ```
     基于现有检索结果和已检索主题，判断是否需要继续检索：
     现有结果：{{finding}}
     已检索主题：{{topic}}
     请返回JSON：{"need_continue": true/false, "next_topic": "补充检索主题（若无需继续则为空）"}
     ```
  3. **补充检索与变量更新**：添加「代码块」，接收全局变量当前值和新检索结果，更新全局变量：
     ```python
     def main(existing_finding: str, existing_topic: list, new_search_topic: str, new_search_result: str) -> dict:
         # 容错处理
         safe_topic = new_search_topic.strip() if isinstance(new_search_topic, str) else ""
         safe_result = str(new_search_result) if new_search_result else "无结果"
         # 仅追加新主题（去重）
         if safe_topic and safe_topic not in existing_topic:
             updated_topic = existing_topic + [safe_topic]
             updated_finding = existing_finding + f"\n【补充检索】\n主题：{safe_topic}\n结果：{safe_result}"
         else:
             updated_topic = existing_topic
             updated_finding = existing_finding
         return {"finding": updated_finding, "topic": updated_topic}  # 覆盖全局变量
     ```
  4. **循环配置**：在Dify工作流中添加「循环节点」，将判断结果`need_continue`作为循环条件，实现动态补充检索。

#### 6.关键问题点
（1） 全局变量设计逻辑
- **为什么使用全局变量**：智能体需跨循环累计检索结果（如第一轮检索“岗位要求”，第二轮补充“关键词优化”），局部变量无法跨循环共享，而全局变量支持全工作流生命周期读写，是实现“累计数据”的唯一方案；
- **更新机制**：遵循「传入当前值→代码块内更新→输出覆盖」的闭环（见步骤3.3代码），每次循环均基于上一轮结果追加，避免数据丢失；
- **容错处理**：通过类型校验（如`isinstance(sub_questions_array, list)`）和默认值（如空字符串/空数组），防止上游数据异常导致全局变量初始化失败。


（2） 循环检索终止条件设计
- 核心逻辑：通过LLM判断「现有检索结果是否足够回答用户问题」，避免检索不足或冗余；
- 结构化输出约束：强制LLM返回`need_continue`（布尔值）和`next_topic`（字符串），通过代码块校验JSON格式，防止判断逻辑失效；
- 兜底机制：设置最大循环次数（如5次），避免无限循环。


（3） 代码块与Dify平台适配
- 遵循Dify规范：所有逻辑封装为`main`函数，输入输出通过变量绑定，替代`print`语句；
- 变量绑定规则：输入变量关联上游节点输出（如`sub_questions_array`关联问题拆解模块），输出变量勾选「覆盖全局变量」实现更新；
- 兼容性处理：支持多类型检索结果（字符串/字典/数组），通过`format_result`函数统一格式（见前期代码优化）。

>[工具地址](https://udify.app/workflow/r4pvX6nY0hqZeZTg)


## 总结：ReAct与DeepResearch的未来方向
ReAct范式的核心价值，在于它首次让AI具备了“人类式问题解决能力”——“边想边做，动态调整”。而DeepResearch作为ReAct的典型实践，进一步将这种能力聚焦于“深度研究场景”，让AI从“文本生成器”升级为“自主研究员”。  

根据腾讯云、通义的技术展望，未来的发展方向将集中在以下几点：  
1. **与多路径规划结合**：将ReAct与“思维树（ToT）”结合——ToT负责在抽象层面规划多套研究方案，ReAct负责具体执行并验证方案可行性；  
2. **降低成本**：通过模型压缩、记忆优化（如动态清理冗余信息），让DeepResearch从“高端功能”走向大众化；  
3. **多模态融合**：在ReAct循环中加入图像、音频工具，覆盖更复杂的研究需求。  


我认为对于开发者而言，掌握ReAct范式不仅是搭建智能体的基础，更是理解“AI如何模拟人类认知”的关键。而DeepResearch的实践则告诉我们：**优秀的AI智能体，不是“无所不能”，而是“像人类一样，知道在什么场景下该做什么、如何调整”**。
